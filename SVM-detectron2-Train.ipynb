{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "** fvcore version of PathManager will be deprecated soon. **\n",
      "** Please migrate to the version in iopath repo. **\n",
      "https://github.com/facebookresearch/iopath \n",
      "\n",
      "** fvcore version of PathManager will be deprecated soon. **\n",
      "** Please migrate to the version in iopath repo. **\n",
      "https://github.com/facebookresearch/iopath \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "import detectron2.data.transforms as T\n",
    "from detectron2.structures.image_list import ImageList\n",
    "from detectron2.utils.visualizer import ColorMode, Visualizer\n",
    "from detectron2.modeling.box_regression import Box2BoxTransform\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import DatasetMapper\n",
    "from detectron2.data import (\n",
    "    build_detection_test_loader,\n",
    "    build_detection_train_loader,\n",
    ")\n",
    "from detectron2.data.samplers import TrainingSampler\n",
    "from detectron2.modeling.proposal_generator.proposal_utils import add_ground_truth_to_proposals\n",
    "from detectron2.modeling.sampling import subsample_labels\n",
    "from detectron2.structures import Boxes, Instances, pairwise_iou\n",
    "from detectron2.modeling.matcher import Matcher\n",
    "from detectron2.modeling.postprocessing import detector_postprocess\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "from fsdet.modeling.roi_heads.fast_rcnn import FastRCNNOutputs\n",
    "from fsdet.evaluation import (\n",
    "    COCOEvaluator, DatasetEvaluators, LVISEvaluator, PascalVOCDetectionEvaluator, verify_results)\n",
    "from fsdet.evaluation import (\n",
    "    DatasetEvaluator,\n",
    "    inference_on_dataset,\n",
    "    print_csv_format,\n",
    "    verify_results,\n",
    ")\n",
    "import cv2\n",
    "import torch, torchvision\n",
    "import logging\n",
    "import os\n",
    "from sklearn import svm\n",
    "from joblib import dump, load\n",
    "from detectron2.layers import nonzero_tuple\n",
    "import numpy as np\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pretrained detection model and Prediect directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models of DNN and SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fvcore.common.checkpoint:Loading checkpoint from checkpoints/coco/faster_rcnn/30shot_airplane_unfreeze_whole/model_0029999.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BGR\n"
     ]
    }
   ],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file('configs/test_unfreeze_lastfews.yaml')\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 100\n",
    "cfg.MODEL.ROI_HEADS.POSITIVE_FRACTION = 0.8\n",
    "model = build_model(cfg)  # returns a torch.nn.Module\n",
    "print(cfg.INPUT.FORMAT)\n",
    "\n",
    "model.eval()\n",
    "metadata = MetadataCatalog.get(cfg.DATASETS.TEST[0])\n",
    "\n",
    "# ckpt_file = 'checkpoints/coco/base_model/model_final.pth'\n",
    "# ckpt_file = 'checkpoints/coco/faster_rcnn/30shot_person_freeze_last_cos/model_final.pth'\n",
    "# ckpt_file = 'checkpoints/coco/faster_rcnn/30shot_person_freeze_last_fc/model_final.pth'\n",
    "# ckpt_file = 'checkpoints/coco/faster_rcnn/30shot_person_unfreeze_lastfews/model_final.pth'\n",
    "# ckpt_file = 'checkpoints/coco/faster_rcnn/30shot_person_unfreeze_whole/model_0015999.pth'\n",
    "ckpt_file = 'checkpoints/coco/faster_rcnn/30shot_airplane_unfreeze_whole/model_0029999.pth'\n",
    "DetectionCheckpointer(model).load(ckpt_file)\n",
    "\n",
    "# clf = load('svm_results/svm_model_finetuned_prop_base.joblib') \n",
    "# clf = load('svm_results/svm_model_finetuned_prop_lastfew.joblib') \n",
    "# clf = load('svm_results/svm_model_finetuned_prop_whole.joblib') \n",
    "shots_num = 500\n",
    "class_name = 'airplane'\n",
    "class_id = 5\n",
    "# [1, 2, 3, 5, 17, 18, 19, 20, 62]: # [person, bicycle, car, airplane, cat, dog, horse, sheep, chair]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "json_dir = 'datasets/coco_experiments/seed1/full_box_{}shot_{}_train.json'.format(shots_num, class_name)\n",
    "image_dir = 'datasets/coco/trainval2014'\n",
    "trainset_name = \"{}shot_{}_train\".format(shots_num, class_name)\n",
    "register_coco_instances(trainset_name, {}, json_dir, image_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference between some dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_loader_train = build_detection_train_loader(cfg)\n",
    "# data_loader_train_it = iter(data_loader_train)\n",
    "# data = next(data_loader_train_it)\n",
    "# # batch size = 16 as is in the config file\n",
    "# print(len(data))\n",
    "# print(data[0]['image'].shape)\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_loader_test = build_detection_test_loader(cfg, \"1000shot_person_test\")\n",
    "# data_loader_test_it = iter(data_loader_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = next(data_loader_test_it)\n",
    "# print(len(data))\n",
    "# print(data[0]['image'].shape)\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:detectron2.data.datasets.coco:\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "INFO:detectron2.data.datasets.coco:Loaded 274 images in COCO format from datasets/coco_experiments/seed1/full_box_500shot_airplane_train.json\n",
      "INFO:detectron2.data.dataset_mapper:[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=[800, 800], max_size=1333)]\n",
      "INFO:detectron2.data.common:Serializing 274 elements to byte tensors and concatenating them all ...\n",
      "INFO:detectron2.data.common:Serialized dataset takes 0.40 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([3, 800, 1196])\n"
     ]
    }
   ],
   "source": [
    "transform_gen = T.ResizeShortestEdge(\n",
    "            [cfg.INPUT.MIN_SIZE_TEST, cfg.INPUT.MIN_SIZE_TEST],\n",
    "            cfg.INPUT.MAX_SIZE_TEST,\n",
    "            )\n",
    "batch_size = 10\n",
    "data_loader = build_detection_train_loader(DatasetCatalog.get(trainset_name),\n",
    "                                           mapper=DatasetMapper(cfg, is_train=True, augmentations=[transform_gen]),\n",
    "                                           total_batch_size = batch_size)\n",
    "data_loader_it = iter(data_loader)\n",
    "data = next(data_loader_it)\n",
    "print(len(data))\n",
    "print(data[0]['image'].shape)\n",
    "# print(data)\n",
    "\n",
    "# the type of dataloader is different 'AspectRatio Grouped Dataset' (don't know the reason) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run detector step by step and get X and y for SVM training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(cfg.MODEL.PIXEL_MEAN) == len(cfg.MODEL.PIXEL_STD)\n",
    "num_channels = len(cfg.MODEL.PIXEL_MEAN)\n",
    "device = 'cuda'\n",
    "pixel_mean = (\n",
    "    torch.Tensor(cfg.MODEL.PIXEL_MEAN)\n",
    "    .to(device)\n",
    "    .view(num_channels, 1, 1)\n",
    ")\n",
    "pixel_std = (\n",
    "    torch.Tensor(cfg.MODEL.PIXEL_STD)\n",
    "    .to(device)\n",
    "    .view(num_channels, 1, 1)\n",
    ")\n",
    "normalizer = lambda x: (x - pixel_mean) / pixel_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from detectron2.utils.events import EventStorage\n",
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "box2box_transform = Box2BoxTransform(\n",
    "            weights=cfg.MODEL.ROI_BOX_HEAD.BBOX_REG_WEIGHTS\n",
    "        )\n",
    "smooth_l1_beta = cfg.MODEL.ROI_BOX_HEAD.SMOOTH_L1_BETA\n",
    "test_score_thresh        = cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST\n",
    "# test_score_thresh        = 0.5\n",
    "test_nms_thresh          = cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST\n",
    "test_detections_per_img  = cfg.TEST.DETECTIONS_PER_IMAGE\n",
    "\n",
    "iter_num = shots_num//batch_size\n",
    "\n",
    "feature_vec_list = []\n",
    "proposals_with_gt = []\n",
    "with EventStorage() as storage:\n",
    "    with torch.no_grad():\n",
    "#         for idx, inputs in enumerate(data_loader_train):\n",
    "#             batched_inputs = inputs\n",
    "        for idx in range(iter_num):\n",
    "            batched_inputs = next(data_loader_it)\n",
    "\n",
    "            # Normalize, pad and batch the input images. (Preprocess_image)\n",
    "            images = [x[\"image\"].to('cuda') for x in batched_inputs]\n",
    "            images = [normalizer(x) for x in images]\n",
    "            images = ImageList.from_tensors(\n",
    "                images, model.backbone.size_divisibility\n",
    "            )\n",
    "\n",
    "            # forward\n",
    "            features = model.backbone(images.tensor)\n",
    "    #         print('features shape:', features['p3'].shape)\n",
    "            proposals, _ = model.proposal_generator(images, features)\n",
    "    #         print('proposal num per img:', proposals_list[0].objectness_logits.shape)\n",
    "\n",
    "            # run roi_heads step by step\n",
    "            targets = [d['instances'].to('cuda') for d in batched_inputs]\n",
    "            proposals = model.roi_heads.label_and_sample_proposals(proposals, targets)\n",
    "\n",
    "            box_features = model.roi_heads.box_pooler(\n",
    "                [features[f] for f in [\"p2\", \"p3\", \"p4\", \"p5\"]], [x.proposal_boxes for x in proposals]\n",
    "            )\n",
    "    #         print(box_features.shape)\n",
    "            box_features = model.roi_heads.box_head(box_features)\n",
    "#             print(box_features.shape) # torch.Size([5120, 1024])\n",
    "\n",
    "            # For SVM training: X and y\n",
    "            feature_vec_list.extend(box_features)\n",
    "            proposals_with_gt.extend(proposals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive : negative =  723  :  2277\n",
      "X shape =  (3000, 1024)\n",
      "y shape =  (3000,)\n"
     ]
    }
   ],
   "source": [
    "# print(len(feature_vec_list))\n",
    "# print(len(proposals_with_gt))\n",
    "X = torch.vstack(feature_vec_list).cpu().detach().numpy()\n",
    "y = torch.vstack([p.gt_classes.reshape((-1, 1)) for p in proposals_with_gt]).cpu().detach().numpy().ravel()\n",
    "y[y==class_id-1] =  0\n",
    "pos_num = y[y==0].shape[0]\n",
    "neg_num = y[y==1].shape[0]\n",
    "print('positive : negative = ', pos_num, ' : ', neg_num)\n",
    "print('X shape = ', X.shape)\n",
    "print('y shape = ', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_30shot_airplane_unfreeze_whole_500_airplane.joblib\n"
     ]
    }
   ],
   "source": [
    "file_name = 'svm_{}_{}_{}.joblib'.format(ckpt_file.split('/')[-2], shots_num, class_name)\n",
    "print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_results_0216/svm_30shot_airplane_unfreeze_whole_500_airplane.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(probability=True)\n",
    "clf.fit(X, y)\n",
    "ckpt_file.split('/')[-2]\n",
    "dump(clf, 'svm_results_0216/' + file_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsdet",
   "language": "python",
   "name": "fsdet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
